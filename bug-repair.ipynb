{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5715981,"sourceType":"datasetVersion","datasetId":1980867},{"sourceId":9862030,"sourceType":"datasetVersion","datasetId":6052820}],"dockerImageVersionId":30177,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install datasets transformers sentencepiece","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-19T13:41:18.791090Z","iopub.execute_input":"2024-11-19T13:41:18.791748Z","iopub.status.idle":"2024-11-19T13:41:26.581765Z","shell.execute_reply.started":"2024-11-19T13:41:18.791638Z","shell.execute_reply":"2024-11-19T13:41:26.581126Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (1.18.4)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.16.2)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (0.1.96)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (4.62.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from datasets) (21.3)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2022.2.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.20.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.1)\nRequirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.26.0)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.4.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (4.11.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets) (3.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.4)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.12.2)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.49)\nRequirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.11.6)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->datasets) (3.0.6)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2021.10.8)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.7)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (21.2.0)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (5.2.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.7.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.6.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2021.3)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.1.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.16.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.3)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\n\nKAGGLE_KERNEL_INTERACTIVE = os.environ[\"KAGGLE_KERNEL_RUN_TYPE\"] == \"Interactive\" and False\n\nif KAGGLE_KERNEL_INTERACTIVE:\n    !pip install huggingface_hub\n    !apt install git-lfs\n    !git lfs install\n\n    from huggingface_hub import notebook_login\n\n    notebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-11-19T13:42:52.055508Z","iopub.execute_input":"2024-11-19T13:42:52.056289Z","iopub.status.idle":"2024-11-19T13:42:52.061723Z","shell.execute_reply.started":"2024-11-19T13:42:52.056252Z","shell.execute_reply":"2024-11-19T13:42:52.060924Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import os\nimport json\nimport torch\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom transformers import RobertaTokenizerFast, T5ForConditionalGeneration, Trainer, TrainingArguments, DataCollatorForSeq2Seq\nfrom datasets import load_dataset\n\nfrom tqdm.notebook import tqdm\nfrom IPython.display import HTML\nfrom functools import partial\nfrom difflib import SequenceMatcher\n\npd.set_option('max_columns', None)\n\ncodenet_root = '/kaggle/input/codenetpy-python-final/codenetpy/'\n\nos.environ[\"WANDB_DISABLED\"] = \"true\"\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"","metadata":{"execution":{"iopub.status.busy":"2024-11-19T13:43:17.553858Z","iopub.execute_input":"2024-11-19T13:43:17.554176Z","iopub.status.idle":"2024-11-19T13:43:17.559762Z","shell.execute_reply.started":"2024-11-19T13:43:17.554147Z","shell.execute_reply":"2024-11-19T13:43:17.559059Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"dataset = load_dataset(\"json\", data_files={\"train\": codenet_root+\"codenetpy_train.json\", \"test\": codenet_root+\"codenetpy_test.json\"}, field='data')","metadata":{"execution":{"iopub.status.busy":"2024-11-19T13:43:20.211851Z","iopub.execute_input":"2024-11-19T13:43:20.212332Z","iopub.status.idle":"2024-11-19T13:43:23.174928Z","shell.execute_reply.started":"2024-11-19T13:43:20.212298Z","shell.execute_reply":"2024-11-19T13:43:23.174144Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-36680e98994034c0/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d22ca55de7d544c4bd084771281e5809"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b00ae42f8fe147ecbce7edd9cae5d5cd"}},"metadata":{}},{"name":"stdout","text":"Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-36680e98994034c0/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6c84dd46db54bd4a1f448eed3aa94ca"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"train_dataset = dataset[\"train\"].filter(lambda example: example[\"returncode\"] != 0).train_test_split(test_size=0.1)\ntest_dataset = dataset[\"test\"]","metadata":{"execution":{"iopub.status.busy":"2024-11-19T13:43:32.307375Z","iopub.execute_input":"2024-11-19T13:43:32.308028Z","iopub.status.idle":"2024-11-19T13:43:33.144812Z","shell.execute_reply.started":"2024-11-19T13:43:32.307971Z","shell.execute_reply":"2024-11-19T13:43:33.144269Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/39 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fb6c4148fef4fff868ab38f33b67e26"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"max_source_length = 256\nmax_target_length = 512\n\ndef tokenize_and_align_labels(tokenizer, example):    \n    tokenized_inputs = tokenizer(text=example[\"error_class_extra\"], text_pair=example[\"original_src\"], max_length=max_source_length, padding=True, truncation=True)\n    tokenized_y = tokenizer(example[\"changed_src\"], max_length=max_target_length, padding=True, truncation=True)\n    \n    labels = tokenized_y.input_ids\n    labels = torch.tensor(labels)\n    labels[labels == tokenizer.pad_token_id] = -100\n\n    tokenized_inputs[\"labels\"] = labels.tolist()\n    return tokenized_inputs\n\ntokenizer = RobertaTokenizerFast.from_pretrained(\"Salesforce/codet5-base\")\n\ntrain_dataset = train_dataset.map(partial(tokenize_and_align_labels, tokenizer), batched=True, batch_size=4, remove_columns=train_dataset[\"train\"].column_names)\ntest_dataset = test_dataset.map(partial(tokenize_and_align_labels, tokenizer), batched=True, batch_size=4, remove_columns=test_dataset.column_names)","metadata":{"execution":{"iopub.status.busy":"2024-11-19T13:43:35.758774Z","iopub.execute_input":"2024-11-19T13:43:35.759061Z","iopub.status.idle":"2024-11-19T13:44:37.124332Z","shell.execute_reply.started":"2024-11-19T13:43:35.759032Z","shell.execute_reply":"2024-11-19T13:44:37.123558Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.44k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90e2b058ff5e4af8a5b33ee5f724bc3c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/687k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a557b204a09401fb6209a094bc0ca83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/287k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ea49178b92e429380b42978d6313d75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8347f4f0fb3c4399880828abd8093dba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/12.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d704cb7d71674adfb418a38b9ed9f035"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/8687 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"347713188f7d4a858e5a22022dfabfb5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/966 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5875cf218144c9d866e54f1901412e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1688 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82a03933c8734563a1e9e7c2ff930da5"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir='codet5-base-buggy-code-repair',                # output directory\n    num_train_epochs=10,                                       # total number of training epochs\n    per_device_train_batch_size=4,                             # batch size per device during training\n    per_device_eval_batch_size=4,                              # batch size for evaluation\n    warmup_steps=500,                                          # number of warmup steps for learning rate scheduler\n    weight_decay=0.01,                                         # strength of weight decay\n    logging_dir='./logs',                                      # directory for storing logs\n    logging_steps=1_000,                                       # Steps to report the loss value\n    save_strategy =\"no\",\n    push_to_hub=KAGGLE_KERNEL_INTERACTIVE,\n)\n\nmodel = T5ForConditionalGeneration.from_pretrained(\"Salesforce/codet5-base\")\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model, padding=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-19T13:44:41.887223Z","iopub.execute_input":"2024-11-19T13:44:41.887537Z","iopub.status.idle":"2024-11-19T13:45:22.352413Z","shell.execute_reply.started":"2024-11-19T13:44:41.887508Z","shell.execute_reply":"2024-11-19T13:45:22.351453Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.53k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b59f9a95290447aab1ad50376fcd17f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/850M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52da32c2a27d42ff86dd6dc6b216cf2b"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"def compute_metrics(p):\n    predictions, labels = p\n    \n    predictions = np.argmax(predictions[0], axis=2)\n   \n    true_predictions = [p for pred in predictions for p in pred]\n    true_labels = [p for pred in labels for p in pred]\n    \n    return {\n        \"precision\": precision_score(true_labels, true_predictions, average=\"weighted\"),\n        \"recall\": recall_score(true_labels, true_predictions, average=\"weighted\"),\n        \"f1\": f1_score(true_labels, true_predictions, average=\"weighted\"),\n        \"accuracy\": accuracy_score(true_labels, true_predictions)\n    }","metadata":{"execution":{"iopub.status.busy":"2024-11-19T13:45:37.921015Z","iopub.execute_input":"2024-11-19T13:45:37.921266Z","iopub.status.idle":"2024-11-19T13:45:37.926415Z","shell.execute_reply.started":"2024-11-19T13:45:37.921240Z","shell.execute_reply":"2024-11-19T13:45:37.925692Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,                         \n    args=training_args,                  \n    train_dataset=train_dataset[\"train\"],  \n    eval_dataset=train_dataset[\"test\"].select(range(10)),    \n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n    data_collator=data_collator,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-11-19T13:45:40.797255Z","iopub.execute_input":"2024-11-19T13:45:40.797853Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n***** Running training *****\n  Num examples = 34745\n  Num Epochs = 10\n  Instantaneous batch size per device = 4\n  Total train batch size (w. parallel, distributed & accumulation) = 4\n  Gradient Accumulation steps = 1\n  Total optimization steps = 86870\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='24909' max='86870' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [24909/86870 3:08:28 < 7:48:52, 2.20 it/s, Epoch 2.87/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1000</td>\n      <td>0.982000</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.543400</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.504100</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.470300</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.464100</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>0.437400</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>0.447000</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>0.430300</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>0.409600</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>0.379800</td>\n    </tr>\n    <tr>\n      <td>11000</td>\n      <td>0.383000</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>0.372100</td>\n    </tr>\n    <tr>\n      <td>13000</td>\n      <td>0.363100</td>\n    </tr>\n    <tr>\n      <td>14000</td>\n      <td>0.360600</td>\n    </tr>\n    <tr>\n      <td>15000</td>\n      <td>0.365900</td>\n    </tr>\n    <tr>\n      <td>16000</td>\n      <td>0.372600</td>\n    </tr>\n    <tr>\n      <td>17000</td>\n      <td>0.361300</td>\n    </tr>\n    <tr>\n      <td>18000</td>\n      <td>0.337400</td>\n    </tr>\n    <tr>\n      <td>19000</td>\n      <td>0.301200</td>\n    </tr>\n    <tr>\n      <td>20000</td>\n      <td>0.307100</td>\n    </tr>\n    <tr>\n      <td>21000</td>\n      <td>0.327600</td>\n    </tr>\n    <tr>\n      <td>22000</td>\n      <td>0.320200</td>\n    </tr>\n    <tr>\n      <td>23000</td>\n      <td>0.313600</td>\n    </tr>\n    <tr>\n      <td>24000</td>\n      <td>0.320100</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2022-06-04T13:02:42.350543Z","iopub.execute_input":"2022-06-04T13:02:42.354745Z","iopub.status.idle":"2022-06-04T13:02:42.987576Z","shell.execute_reply.started":"2022-06-04T13:02:42.354703Z","shell.execute_reply":"2022-06-04T13:02:42.986867Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict(tokenizer, model, error, source, beam_size=5):\n    tokenized_inputs = tokenizer(text=error, text_pair=source, max_length=512, padding=True, truncation=True, return_tensors=\"pt\").to(model.device)\n    tokenized_labels = model.generate(num_beams=beam_size, no_repeat_ngram_size=2, num_return_sequences=beam_size, max_length=512, **tokenized_inputs).cpu().detach().numpy()\n\n    return tokenizer.batch_decode(tokenized_labels, skip_special_tokens=True)\n\ndef compute_accuracy(beam_sizes, total=1000, dataset=dataset[\"test\"]):\n    correct_preds = [0 for _ in beam_sizes]\n    \n    for i in tqdm(range(total)):\n        preds = predict(tokenizer, model, [dataset[i][\"error_class_extra\"]], [dataset[i][\"original_src\"]], beam_size=beam_sizes[-1])\n\n        for j, pred in enumerate(preds):\n            if pred == dataset[i][\"changed_src\"]:\n                for k in range(len(correct_preds)):\n                    if j < beam_sizes[k]:\n                        correct_preds[k] += 1\n                break\n                \n    for b, c in zip(beam_sizes, correct_preds):\n        print(f\"Accuracy beam_size={b} {c / total}\")\n\ncompute_accuracy(beam_sizes=[1, 5, 10, 50])","metadata":{"execution":{"iopub.status.busy":"2022-06-04T13:57:10.776966Z","iopub.execute_input":"2022-06-04T13:57:10.77725Z","iopub.status.idle":"2022-06-04T14:03:56.309571Z","shell.execute_reply.started":"2022-06-04T13:57:10.777218Z","shell.execute_reply":"2022-06-04T14:03:56.308855Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if KAGGLE_KERNEL_INTERACTIVE:\n    trainer.push_to_hub()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T14:03:50.312547Z","iopub.execute_input":"2022-05-06T14:03:50.312811Z","iopub.status.idle":"2022-05-06T14:06:30.784052Z","shell.execute_reply.started":"2022-05-06T14:03:50.312778Z","shell.execute_reply":"2022-05-06T14:06:30.782955Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_char_mask(original_src, changed_src):\n    s = SequenceMatcher(None, original_src, changed_src)\n    opcodes = [x for x in s.get_opcodes() if x[0] != \"equal\"]\n    \n    original_labels = np.zeros_like(list(original_src), dtype=np.int32)\n    for _, i1, i2, _, _ in opcodes:\n        original_labels[i1: max(i1+1, i2)] = 1\n\n    return original_labels.tolist()\n\ndef color_source(source_code, mask, color='red'):\n    text = \"\"\n    for i, char in enumerate(source_code):\n        norm_color = 'black'\n        if char == ' ':\n            char = \"•\"\n            norm_color = 'lightgrey'\n        if char == '\\n':\n            char = \"↵\\n\"\n            norm_color = 'lightgrey'\n        text += f'<span style=\"color:{color if mask[i] == 1 else norm_color};\">{char}</span>'\n    return \"<pre>\" + text + \"</pre>\"","metadata":{"execution":{"iopub.status.busy":"2022-06-04T13:02:42.989131Z","iopub.execute_input":"2022-06-04T13:02:42.989408Z","iopub.status.idle":"2022-06-04T13:02:42.9996Z","shell.execute_reply.started":"2022-06-04T13:02:42.989356Z","shell.execute_reply":"2022-06-04T13:02:42.998797Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i in range(50):\n    display(HTML(f\"<h2>Example {i}</h2>\"))\n    \n    display(HTML(f\"<h3>Source Code</h3>\"))\n    mask = generate_char_mask(dataset[\"test\"][i][\"original_src\"], dataset[\"test\"][i][\"changed_src\"])\n    display(HTML(color_source(dataset[\"test\"][i][\"original_src\"], mask)))\n    \n    display(HTML(f\"<h3>Accepted Source Code</h3>\"))\n    print(dataset[\"test\"][i][\"changed_src\"])\n    \n    display(HTML(f\"<h3>Error Description</h3>\"))\n    print(dataset[\"test\"][i][\"error_class_extra\"])\n    \n    display(HTML(f\"<h3>Prediction Source Code</h3>\"))\n    preds = predict(tokenizer, model, [dataset[\"test\"][i][\"error_class_extra\"]], [dataset[\"test\"][i][\"original_src\"]], beam_size=5)\n    for pred in preds:\n        print()\n        print(pred)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T13:02:43.001109Z","iopub.execute_input":"2022-06-04T13:02:43.001597Z","iopub.status.idle":"2022-06-04T13:03:35.577963Z","shell.execute_reply.started":"2022-06-04T13:02:43.001561Z","shell.execute_reply":"2022-06-04T13:03:35.577222Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}